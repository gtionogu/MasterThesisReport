
\chapter{Model creation} % Main chapter title

\label{Model creation}
%source Botnet_Detection_Based_On_Machine_Learning_Techniques_Using_DNS_Query_Data\\
Experiment Dataset Pre-Processing = feature extraction (I LIKE HOW HE EXPLAIN BI-TRI GRAMS)
\section{Pipeline of the research}
\subsection{Environment}
\subsection{Datasets}
TODO: reformat the dataset section.

Since some of the implementations that we are going to compare have a blacklist step, we have done a large research on the blacklists available. At first we only focused on botnets domains and IPs, but then realized that bots can query their C2 but also try to access any malicious domain or IP, either to upload or download relevant data for the bot. Therefore, the final blacklist used is a very large combination of blacklists that go from domains linked to malware or C2 to domains linked to suspicious phishing/adware campaigns. One of the websites that really helped in this process is \url{https://firebog.net/}. All these lists have been combined into a big unique blacklist used in some of the approaches presented here.\\\\

The first idea was to use basics lists with an additional check with the virusTotal API but it is a very long process et the amount of lookups is limited therefore not a viable solution. Instead we researched the blacklists used by virusTotal and other DNSBL providers and have a very long static list instead.

%--------------------

% Explain the different datasets
Let us talk about the datasets used to train the different classifiers and algorithms used in the thesis.\\
This is going to be very dependent on the approach, for unsupervised algorithms, we are going to train them with clean traffic and see its reaction to malicious traffic. For classification algorithms we are going to go for model training for manual tagging of traffic that is either malicious or clean.
The idea will be to test the algorithms on parts of the sets but also try them on completely different traffic and compare the results.
\\

Depending on the algorithms the datasets aren't the same, for supervised approaches, there is a need of labelled data. For that we have searched for unique DNS traffic coming from Botnets combined with clean generic traffic. We create different combinations of traffic to improve our understanding of what works in what scenarios.\\


The datasets used in this thesis come from different sources that try to provide labelled data or precise data from botnets. These different sources are the CIS (Canadian institute of Security) that provide datasets created for the research related to security on traffic, specifically for machine learning techniques. They have labelled data from a lot of different sources and protocols. The one they provided me is focused on different types of botnets.
The ISOT Http Botnet dataset consists of 2 different datasets: malicious DNS traffic generated by multiple botnets and benign traffic generated by generic software. 

The ISOT Botnet dataset which consists in a large dataset regrouping 9 malicious botnets traffic in a controlled environment. 
And finally the CTU scenarios provided by the malware capture facility project.

\section{Purpose of datasets}
The idea of having different datasets allows to understand if some techniques work against a large variety of evasion techniques or on specific ones. This also can be a way to propose complete feature set for complete detections.
\\
Finding proper datasets with botnet traffic with malicious DNS traces is not an easy thing to achieve. Luckily, the CIC team were kind enough to allow me to use their dataset designed for botnet traffic analysis. We also found a dataset proposed by the CTU which is a set of 13 scenarios that represent different types of malicious traffic generated by botnets. The CTU dataset was not as rich in DNS traffic as the other ones, but provided with fast flux traffic to test some of the features proposed to detect FF.

\section{Presentation of the datasets}
\subsection{CIC}
This is a dataset maintained by the Canadian Institute for Cybersecurity. The have compiled malicious traffic from different sources and for most of them the traces are labelled which is very convenient for machine learning supervised approaches.\\ 
The dataset they provide for Botnet traffic analysis is composed of 9 different Botnets and of 2 datasets, a training and a testing dataset. Unfortunately, even being the largest labelled  dataset, the DNS traffic was low. 
\subsection{CTU}
This is a set of datasets provided by the malware capture facility project\cite{CTU}. It captures malicious traffic from different malwares then provide them to the public for research. They also provide their own analysis on most of the datasets which provides insight on how the malware act and how it can be detected.\\
The scenarios that interest us are: the 5th and the 13th that include Fast-Flux labelled traffic.
It also provides hundreds of additional datasets but that are not as well documents and presented which makes the research for a particular dataset more complicated.
\subsection{ISOT}
This is a dataset specifically build around DNS traffic by the The ISOT Lab from the University of Victoria. It regroups 9 exploit kits ran in virtual environments in a closed network with a custom DNS server to snif all the traffic. This dataset provides us with 3 sets of traces, malicious, bening and a mix\cite{ISOT}.
\subsection{Processing}
Because of the amount of different features tested in the thesis. I decided to use 2 pcap extractors. The first was provided by our teacher Prof. J. Colin which is a very effective extractor and summarizes very well the relevant data for most of the features but for labelling and some of the features, more information was required. What we did to obtain a second extractor to complement the information was to run the traffic datasets through Bro, the network IDS. This provided us with DNS.logs, that we then converted using the python "bat" library which converts directly bro logs to dataframes.\\
Most of the labelled datasets actually only provided the IP addresses of the malicious traffic, this is why working with the bro logs was essential to label the datasets.


\subsubsection{Information regarding the datasets}
Sources\\
Content\\
Labelling\\
\subsubsection{balancing the datasets}
\section{Assessment model (for features and models)}
\subsection{Machine algorithms}
\subsubsection{Supervised}
List of algorithms (to be decided)
\subsubsection{Unsupervised for feature extraction}
List of algorithms (to be decided)
\subsection{Training model}
\subsection{Testing model}
\subsection{Results metrics}
List of metrics used to analyse the models 
