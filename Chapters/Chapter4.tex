% Chapter 1

\chapter{All-in solution process} 
\label{All-in solution process} 

\section{Features extraction and features analysis}
%source Botnet_Detection_Based_On_Machine_Learning_Techniques_Using_DNS_Query_Data\\
Experiment Dataset Pre-Processing = feature extraction (I LIKE HOW HE EXPLAIN BI-TRI GRAMS)


Explain all the pre-computation done to obtain certain features.

\subsection{Domain-flux Features}

\cite{dga}
They propose these features to detect DGAs:\\\\
\begin{tabular}{|l|}
\hline
length of the domain name excluding TLD (top level domain)\\
\hline
Number of vowels in the Second Level Domain (SLD)\\
\hline
Number of consonants in the SLD\\
\hline
Number of digits in the SLD\\
\hline
SLD trigram entropy\\
\hline
SLD trigram conditional probability\\
\hline
\end{tabular}

\subsection{Fast-flux features}

\cite{honeynet}
\cite{ff2}
\cite{ff3}
\cite{ff_botconf}
\begin{tabular}{|l|}
\hline
Numerous unique A records for a domain\\
\hline
Numerous unique NS records for a  domain\\
\hline
Different Autonomous Systems (ASN) for the IPs of linked to the same domain\\
\hline
Different countries\cite{dga}
They propose these features to detect DGAs:\\\\
\begin{tabular}{|l|}
\hline
length of the domain name excluding TLD (top level domain)\\
\hline
Number of vowels in the Second Level Domain (SLD)\\
\hline
Number of consonants in the SLD\\
\hline
Number of digits in the SLD\\
\hline
SLD trigram entropy\\
\hline
SLD trigram conditional probability\\
\hline
\end{tabular} for the IPs of linked to the same domain\\
\hline
Short Time-To-Live (TTL)\\
\hline
\end{tabular}

\cite{ff1}
Some features for FF detection: 
nb of A records returned: 1-3 normal, 5 or more ff 
nb of NS: normal -> small, ff -> several NS
several A records for the NS AS: small nb of A from 1 AS -> normal,
located in different AS -> ff 
Hardware and IP: range of IP is diverged -> ff 
No physical agent -> ff 
no guarantee uptime -> ff

\cite{ff3}
\textbf{Fluxiness} is the total of unique A records for a domain divided by the number of A records returned for each lookup. This measures consistency in the unique A records returned. \\
\textbf{Flux-score} an hyperplane that separates benign from malicious fast flux where $ x = (n_A,n_{ASN},n_{NS})$ (unique A records, ASN and SN records) and the plane is defined as follows\\
%\begin{equation}
%F(x) = 
%\begin{cases}
%   w^Tx-b > 0  & \text{x is a FFSN}\\
%   w^Tx-b \leq 0 & \text{x is CDN}\\
%\end{cases}
%\end{equation}
From $F(x)$ they induce a metric $f(x) = w^Tx$ with w the weight of the vector and b a bias. $f(x) > b$ would mean x is a FFSN. By empirically testing this on a labelled dataset they determined the value of w and b. $w = (1.32,18.54,0)$ and $b =142.38$. We can notice that $n_{NS}$ does not have any impact.

\cite{fluXOR}
\begin{tabular}{|l|}
\hline
Number of resolved IPs\\
\hline
Number of domains (in a cluster = domains with similar IPs)\\
\hline
Avg. TTL per domain in a cluster\\
\hline
Network prefix diversity = ratio between the number of distinct\\ /16 network prefixes and the total \\
\hline
number of IPs (measures the scattering)\\
\hline
Number of distinct domain names that resolved to at least one of \\the IP addresses in the considered cluster\\
\hline
IP Growth Ratio. This represents the average number
of new IP\\ addresses discovered per each DNS response related to any domain\\
\hline
\end{tabular}
\\\\
Then the active ones:\\\\
\begin{tabular}{|l|}
\hline
Autonomous System (AS) diversity (ratio between the number of distinct\\ ASs where the IPs of a cluster reside and the total number of resolved IPs. \\Same for the following diversities)\\
\hline
BGP prefix diversity\\
\hline
Organization diversity\\
\hline
Country Code diversity\\
\hline
Dynamic IP ratio (ratio of dynamic vs total IPs using keywords in reverse\\ DNS lookups)\\
\hline
Average Uptime Index (average uptime for the IPs in a cluster,\\ Uptime tested through probing)\\
\hline
\end{tabular}

\cite{ff5}
\begin{tabular}{c|l}
Type & Features\\
\hline
 & Number of unique A records\\
DNS Answer-based &  Number of NS records\\
 & DNS packet size\\
 & TC (Tnmcated) Flag is set\\
\hline
 & Edit Distance\\
Domain name-based & KL (Kullback-Leibler) Divergence (unigrams and bigrams)\\
 & Jaccard Index (unigrams and bigrams)\\
\hline
 & Time Zone Entropy of A records\\
Spatial-based & Time Zone Entropy of NS records\\
 & Minimal service distances (mean and standard deviation)\\
\hline
 & Number of distinct autonomous systems\\
Network-based & Number of distinct networks\\
 \hline
 & Round Trip Time of DNS request\\
Timing-based & Network delay (mean and standard deviation)\\
& Processing delay (mean and standard deviation)\\
& Document fetch delay (mean and standard deviation)\\
\end{tabular}


\subsection{DNS tunnelling features}


\subsection{All-in}
\cite{exposure}
\paragraph{Time-based}
When we analyse many requests to a particular domain over
time, patterns indicative of malicious behaviour may emerge.\\
These were supposed to be the features with the most weight, unfortunately due to lack of the same caliber of capture available to the authors of Exposure, we could not test out the 4 features related to time. Either because the datasets are compositions of smaller datasets, or because the timestamps are too short.
\paragraph{DNS answer based}
Here are some domain-flux features: A domain name can map to multiple IP addresses. In such cases,the DNS server cycles through the different IP addresses in a round robin fashion and returns a different IP mapping each time. \\
Malicious domains typically resolve to compromised computers that reside in different locations. The attackers typically use domains that map to multiple IP addresses, and IPs might be shared across different domains.
\begin{itemize}[noitemsep]
\item the number of different IP addresses that are resolved for a given domain during the experiment window
\item the number of different countries that these IP addresses are located in
\item the reverse DNS query results of the returned IP addresses
\item the number of distinct domains that share the IP addresses that resolve to the given domain (false positive can be reduced with google reverse DNS which will have hosting providers in top answers)
\end{itemize}
\paragraph{TTL value based}
Low TTL and Round-Robin DNS: \\
\begin{itemize}[noitemsep]
\item high availability (Content Delivery Networks (CDNs))
\item botnets using this, makes them resistant to DNS Blacklists(DNSBL) and take downs. Often using Fast-Flux Service Networks (FFSN).
\end{itemize}
Because FFSN are usually detectable because of low TTL and growing list of distinct IP addresses for a domain, it explains the purpose of the TTL features.
\paragraph{Domain name based}
Finally 2 simple features to expect detection of DGA: there is a big difference between legit domain names and domains generated by DGAs(Domain Generation Algorithms(DGAs).\\
This can be noticed with 2 simple features:\\
\begin{itemize}[noitemsep]
\item ratio numerical chars to length of domain name
\item length of the longest meaningful substring to length of domain name
\end{itemize}



%Number of resolved IPs.
%Number of domains
%Avg. TTL per domain
%Number of domains per network
%IP diversity
%IP Growth Ratio
%IP Last Growth Ratio 
%IP Prefixes Last Growth Ratio

\subsection{Features analysis}
Distribution of the features for the different datasets,Correlation between features
\subsection{Features discussion}
\section{Features selection for All-in solution}
\subsection{Feature optimization cycle (adding/removing features, changing or modifying thresholds )}
\section{Comparison of the results}